\BOOKMARK [0][-]{chapter.1}{Theory}{}% 1
\BOOKMARK [1][-]{section.1.1}{Introduction}{chapter.1}% 2
\BOOKMARK [2][-]{subsection.1.1.1}{Incoherence of the low rank component L0}{section.1.1}% 3
\BOOKMARK [2][-]{subsection.1.1.2}{Support of the sparse component S0}{section.1.1}% 4
\BOOKMARK [1][-]{section.1.2}{Main Result}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.3}{Proof of the main result}{chapter.1}% 6
\BOOKMARK [2][-]{subsection.1.3.1}{Preliminaries}{section.1.3}% 7
\BOOKMARK [2][-]{subsection.1.3.2}{Elimination Theorem}{section.1.3}% 8
\BOOKMARK [2][-]{subsection.1.3.3}{Derandomization}{section.1.3}% 9
\BOOKMARK [2][-]{subsection.1.3.4}{Dual certificate}{section.1.3}% 10
\BOOKMARK [2][-]{subsection.1.3.5}{Probabilistic Guarantee via Dual Certification}{section.1.3}% 11
\BOOKMARK [2][-]{subsection.1.3.6}{Proof of the Lemma about golfing scheme and dual certificate }{section.1.3}% 12
\BOOKMARK [2][-]{subsection.1.3.7}{Proof of the Lemma about least square construction and dual certificate }{section.1.3}% 13
\BOOKMARK [2][-]{subsection.1.3.8}{Proof of the equivalence of the Bernoulli sampling and uniform sampling model }{section.1.3}% 14
\BOOKMARK [2][-]{subsection.1.3.9}{Proof of the form of sub-differential of nuclear norm }{section.1.3}% 15
\BOOKMARK [1][-]{section.1.4}{Related Problems and Extensions}{chapter.1}% 16
\BOOKMARK [2][-]{subsection.1.4.1}{Exact Matrix completion}{section.1.4}% 17
\BOOKMARK [2][-]{subsection.1.4.2}{Stable Principal Component Pursuit}{section.1.4}% 18
\BOOKMARK [2][-]{subsection.1.4.3}{Robust Alignment by Sparse and Low-rank Decomposition}{section.1.4}% 19
\BOOKMARK [2][-]{subsection.1.4.4}{Robust Matrix Decomposition With Sparse Corruptions}{section.1.4}% 20
\BOOKMARK [1][-]{section.1.5}{Robust PCA with known rank: a block coordinate descent approach}{chapter.1}% 21
\BOOKMARK [2][-]{subsection.1.5.1}{Motivation}{section.1.5}% 22
\BOOKMARK [2][-]{subsection.1.5.2}{Equivalent formulation of Robust PCA with rank information}{section.1.5}% 23
\BOOKMARK [2][-]{subsection.1.5.3}{Simplification using 1 heuristic}{section.1.5}% 24
\BOOKMARK [2][-]{subsection.1.5.4}{Algorithms derivation}{section.1.5}% 25
\BOOKMARK [2][-]{subsection.1.5.5}{Sensitivity to }{section.1.5}% 26
\BOOKMARK [2][-]{subsection.1.5.6}{Simulation }{section.1.5}% 27
\BOOKMARK [0][-]{chapter.2}{Algorithms}{}% 28
\BOOKMARK [1][-]{section.2.1}{Overview}{chapter.2}% 29
\BOOKMARK [1][-]{section.2.2}{Main algorithms for Robust PCA}{chapter.2}% 30
\BOOKMARK [2][-]{subsection.2.2.1}{Interior Point Methods}{section.2.2}% 31
\BOOKMARK [2][-]{subsection.2.2.2}{Iterative Thresholding Method}{section.2.2}% 32
\BOOKMARK [2][-]{subsection.2.2.3}{Accelerated Proximal Gradient Method}{section.2.2}% 33
\BOOKMARK [2][-]{subsection.2.2.4}{Gradient Ascent on the Dual}{section.2.2}% 34
\BOOKMARK [2][-]{subsection.2.2.5}{Augmented Lagrangian Method}{section.2.2}% 35
\BOOKMARK [1][-]{section.2.3}{Discussion of the Algorithms}{chapter.2}% 36
\BOOKMARK [2][-]{subsection.2.3.1}{The Importance of the SVD}{section.2.3}% 37
\BOOKMARK [2][-]{subsection.2.3.2}{Numerical Comparison of Robust PCA algorithms}{section.2.3}% 38
\BOOKMARK [2][-]{subsection.2.3.3}{Possible Directions for Parallelization}{section.2.3}% 39
\BOOKMARK [1][-]{section.2.4}{Outlook: Algorithms for Stable Principal Component Pursuit}{chapter.2}% 40
\BOOKMARK [0][-]{chapter.3}{Applications}{}% 41
\BOOKMARK [1][-]{section.3.1}{Overview}{chapter.3}% 42
\BOOKMARK [1][-]{section.3.2}{Robust PCA Applications}{chapter.3}% 43
\BOOKMARK [2][-]{subsection.3.2.1}{Background modeling from surveillance video}{section.3.2}% 44
\BOOKMARK [2][-]{subsection.3.2.2}{Using Robust PCA in speech recognition}{section.3.2}% 45
\BOOKMARK [2][-]{subsection.3.2.3}{Senate voting data analysis}{section.3.2}% 46
\BOOKMARK [2][-]{subsection.3.2.4}{Pre-processing of Brain-Machine Interface neural spike data}{section.3.2}% 47
\BOOKMARK [1][-]{section.3.3}{Discussion}{chapter.3}% 48
